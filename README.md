# SAGE Identity-AI

XLM-RoBERTa ê¸°ë°˜ í† í° ë¶„ë¥˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ ì´ë©”ì¼, ì „í™”ë²ˆí˜¸ ë“± ê°œì¸ì‹ë³„ì •ë³´(PII)ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ íƒì§€í•˜ëŠ” FastAPI ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

## ì£¼ìš” ê¸°ëŠ¥

- **PII ìŠ¤íŒ¬ íƒì§€**: ì´ë©”ì¼, ì „í™”ë²ˆí˜¸, ì´ë¦„, ì£¼ì†Œ ë“± ê°œì¸ì •ë³´ ìœ„ì¹˜ì™€ ìœ í˜•ì„ ì •í™•í•˜ê²Œ ì‹ë³„
- **ë‹¤êµ­ì–´ ì§€ì›**: XLM-RoBERTa ê¸°ë°˜ìœ¼ë¡œ í•œêµ­ì–´, ì˜ì–´ ë“± 100ê°œ ì´ìƒ ì–¸ì–´ ì²˜ë¦¬
- **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ ë¬¸ì¥ì„ í•œ ë²ˆì— ë¶„ì„í•  ìˆ˜ ìˆëŠ” ë°°ì¹˜ ì—”ë“œí¬ì¸íŠ¸ ì§€ì›
- **CORS ì„¤ì •**: ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ì˜ í†µí•©ì„ ìœ„í•œ CORS ì§€ì›
- **ìë™ ë¬¸ì„œí™”**: Swagger UIë¥¼ í†µí•œ ëŒ€í™”í˜• API ë¬¸ì„œ ì œê³µ
- **ìŠ¤ì½”ì–´ í•„í„°ë§**: ì‹ ë¢°ë„ ì„ê³„ê°’ì„ í†µí•œ ì •ë°€í•œ íƒì§€ ì œì–´

## ë¹ ë¥¸ ì‹œì‘

### ì›í´ë¦­ ë°°í¬
```bash
#!/bin/bash

# ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
PID=$(lsof -ti tcp:8900 || true)
if [ -n "$PID" ]; then
  echo "í¬íŠ¸ 8900 ì‚¬ìš© ì¤‘ -> PID: $PID ì¢…ë£Œ"
  sudo kill -9 $PID
fi

# í”„ë¡œì íŠ¸ í´ë¡ 
git clone https://github.com/BOB-DSPM/SAGE_Identity-AI
cd SAGE_Identity-AI

# Python ê°€ìƒí™˜ê²½ ì„¤ì •
python3 -m venv .venv
source .venv/bin/activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
pip install torch --index-url https://download.pytorch.org/whl/cpu

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ
sudo apt install wget tar zstd -y
wget https://github.com/BOB-DSPM/SAGE_Identity-AI/releases/download/v0.1.0/xlmr-large-min.tar.zst
tar --zstd -xf xlmr-large-min.tar.zst

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ë° ì„œë²„ ì‹œì‘
export MODEL_DIR=./xlmr-large-min
nohup python3 -m uvicorn app.main:app --host 0.0.0.0 --port 8900 > iden-ai.log 2>&1 & echo $! > iden-ai.pid

echo "âœ… ì„œë²„ ì‹œì‘ ì™„ë£Œ!"
echo "ğŸ“ API ë¬¸ì„œ: http://localhost:8900/docs"
```

### í™˜ê²½ êµ¬ì„±
```bash
# ê°€ìƒí™˜ê²½ ì„¤ì •
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
pip install torch --index-url https://download.pytorch.org/whl/cpu

# GPU ì‚¬ìš© ì‹œ (CUDA 12.1)
# pip install torch --index-url https://download.pytorch.org/whl/cu121
```

### ì„œë²„ ì‹¤í–‰
```bash
# ë¡œì»¬ ì‹¤í–‰ (í¬íŠ¸ 8900)
python3 -m uvicorn app.main:app --host 0.0.0.0 --port 8900 --reload

# ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
nohup python3 -m uvicorn app.main:app --host 0.0.0.0 --port 8900 > iden-ai.log 2>&1 & echo $! > iden-ai.pid
```

API ë¬¸ì„œ: http://localhost:8900/docs

## í”„ë¡œì íŠ¸ êµ¬ì¡°
```
SAGE_Identity-AI/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py           # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”‚   â”œâ”€â”€ main.py               # FastAPI ì—”ë“œí¬ì¸íŠ¸
â”‚   â””â”€â”€ runtime.py            # PiiModel í´ë˜ìŠ¤ (ëª¨ë¸ ë¡œë“œ ë° ì¶”ë¡ )
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_smoke.py         # ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ (FakeModel ì‚¬ìš©)
â”œâ”€â”€ xlmr-large-min/           # ëª¨ë¸ íŒŒì¼ ë””ë ‰í„°ë¦¬ (ì••ì¶• í•´ì œ í›„)
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ .env.example              # í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿
â”œâ”€â”€ .gitignore                # Git ì œì™¸ íŒŒì¼ ëª©ë¡
â”œâ”€â”€ dockerfile                # Docker ì´ë¯¸ì§€ ë¹Œë“œ íŒŒì¼
â”œâ”€â”€ README.md                 # í”„ë¡œì íŠ¸ ë¬¸ì„œ
â”œâ”€â”€ requirements.txt          # Python ì˜ì¡´ì„± ëª©ë¡
â”œâ”€â”€ run.sh                    # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ xlmr-large-min.tar.zst    # ëª¨ë¸ ì••ì¶• íŒŒì¼
â””â”€â”€ xlmr-large-min.tar.zst.sha256
```

## API ì—”ë“œí¬ì¸íŠ¸

### ê¸°ë³¸ ì •ë³´
```bash
# ë£¨íŠ¸
GET /

# Health Check
GET /health

# ì§€ì› ë¼ë²¨ ì¡°íšŒ
GET /labels
```

### PII íƒì§€
```bash
# ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¶„ì„
POST /infer
Content-Type: application/json
{
  "text": "ì—°ë½ì²˜ëŠ” alice@example.com ë˜ëŠ” 010-1234-5678ì…ë‹ˆë‹¤.",
  "mask": false
}

# ë°°ì¹˜ ë¶„ì„
POST /infer/batch
Content-Type: application/json
{
  "texts": [
    "ë¬¸ì˜: support@company.com",
    "ì „í™”ë²ˆí˜¸ëŠ” 02-1234-5678",
    "ê°œì¸ì •ë³´ ì—†ëŠ” í…ìŠ¤íŠ¸"
  ],
  "mask": false
}
```

## ì‘ë‹µ ì˜ˆì‹œ

### Health Check
```json
{
  "ok": true,
  "model_dir": "./xlmr-large-min",
  "device": "cpu",
  "labels": ["EMAIL", "PHONE", "PERSON", "ADDRESS"],
  "init_error": null
}
```

### ë‹¨ì¼ ë¶„ì„
```json
{
  "text": "ì—°ë½ì²˜ëŠ” alice@example.com ë˜ëŠ” 010-1234-5678ì…ë‹ˆë‹¤.",
  "spans": [
    {
      "start": 6,
      "end": 24,
      "label": "EMAIL",
      "text": "alice@example.com",
      "score": 0.9876
    },
    {
      "start": 29,
      "end": 42,
      "label": "PHONE",
      "text": "010-1234-5678",
      "score": 0.9654
    }
  ],
  "masked": null
}
```

### ë°°ì¹˜ ë¶„ì„
```json
{
  "results": [
    {
      "text": "ë¬¸ì˜: support@company.com",
      "spans": [
        {
          "start": 4,
          "end": 23,
          "label": "EMAIL",
          "text": "support@company.com",
          "score": 0.9912
        }
      ]
    },
    {
      "text": "ì „í™”ë²ˆí˜¸ëŠ” 02-1234-5678",
      "spans": [
        {
          "start": 7,
          "end": 19,
          "label": "PHONE",
          "text": "02-1234-5678",
          "score": 0.9543
        }
      ]
    },
    {
      "text": "ê°œì¸ì •ë³´ ì—†ëŠ” í…ìŠ¤íŠ¸",
      "spans": []
    }
  ]
}
```

## í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ ìƒì„±:
```bash
MODEL_DIR=./xlmr-large-min
DEVICE=cpu                    # cpu, cuda:0, auto
AGGREGATION_STRATEGY=simple   # simple, average, first, max
SCORE_THRESHOLD=0.5           # ìµœì†Œ ì‹ ë¢°ë„ ì ìˆ˜ (ì„ íƒ)
WARMUP=1                      # ì´ˆê¸° ì›Œë°ì—… ì—¬ë¶€ (0, 1)
CORS_ALLOW_ORIGINS=           # ì¶”ê°€ í—ˆìš© ì˜¤ë¦¬ì§„ (ì‰¼í‘œ êµ¬ë¶„)
```

| ë³€ìˆ˜ëª… | ì„¤ëª… | ê¸°ë³¸ê°’ | ì˜ˆì‹œ |
|--------|------|--------|------|
| `MODEL_DIR` | ëª¨ë¸ íŒŒì¼ ë””ë ‰í„°ë¦¬ ê²½ë¡œ | `./models/xlm-roberta-large` | `./xlmr-large-min` |
| `DEVICE` | ì¶”ë¡  ë””ë°”ì´ìŠ¤ | ìë™ ê°ì§€ | `cpu`, `cuda:0` |
| `AGGREGATION_STRATEGY` | í† í° ë³‘í•© ì „ëµ | `simple` | `simple`, `average`, `first`, `max` |
| `SCORE_THRESHOLD` | ìµœì†Œ ì‹ ë¢°ë„ ì ìˆ˜ í•„í„°ë§ | ì—†ìŒ | `0.5`, `0.7` |
| `WARMUP` | ì´ˆê¸° ì›Œë°ì—… ì¶”ë¡  ì‹¤í–‰ | `1` | `0`, `1`, `false` |
| `CORS_ALLOW_ORIGINS` | ì¶”ê°€ í—ˆìš© ì˜¤ë¦¬ì§„ | ë¡œì»¬ ì£¼ì†Œ | `https://example.com` |

## ë°ì´í„° ì²˜ë¦¬ íë¦„
```
1. ìš”ì²­ ìˆ˜ì‹  (FastAPI)
   â†“
2. ì…ë ¥ ê²€ì¦ (Pydantic)
   â†“
3. í† í¬ë‚˜ì´ì € ì²˜ë¦¬ (AutoTokenizer)
   â†“
4. ëª¨ë¸ ì¶”ë¡  (AutoModelForTokenClassification)
   â†“
5. í† í° ë³‘í•© (Pipeline aggregation_strategy)
   â†“
6. ìŠ¤ì½”ì–´ í•„í„°ë§ (SCORE_THRESHOLD)
   â†“
7. ìŠ¤íŒ¬ ì •ë³´ ìƒì„± (start/end/label/text/score)
   â†“
8. JSON ì‘ë‹µ (FastAPI)
```

## Frontend ì—°ë™

### API í˜¸ì¶œ ì˜ˆì‹œ (TypeScript)
```typescript
// ë‹¨ì¼ ë¶„ì„
const response = await fetch('http://localhost:8900/infer', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: 'ì—°ë½ì²˜: alice@example.com'
  })
});
const data = await response.json();

// ë°°ì¹˜ ë¶„ì„
const batchResponse = await fetch('http://localhost:8900/infer/batch', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    texts: ['í…ìŠ¤íŠ¸1', 'í…ìŠ¤íŠ¸2', 'í…ìŠ¤íŠ¸3']
  })
});
const batchData = await batchResponse.json();
```

### Python í´ë¼ì´ì–¸íŠ¸
```python
import requests

BASE_URL = "http://localhost:8900"

# ë‹¨ì¼ ë¶„ì„
response = requests.post(
    f"{BASE_URL}/infer",
    json={"text": "ì—°ë½ì²˜: alice@example.com"}
)
result = response.json()

# ë°°ì¹˜ ë¶„ì„
response = requests.post(
    f"{BASE_URL}/infer/batch",
    json={"texts": ["í…ìŠ¤íŠ¸1", "í…ìŠ¤íŠ¸2"]}
)
results = response.json()
```


## í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ
```bash
# 1. Health Check
curl http://localhost:8900/health

# 2. ì§€ì› ë¼ë²¨ ì¡°íšŒ
curl http://localhost:8900/labels

# 3. ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¶„ì„
curl -X POST http://localhost:8900/infer \
  -H "Content-Type: application/json" \
  -d '{"text": "ë©”ì¼: test@example.com"}'

# 4. ë°°ì¹˜ ë¶„ì„
curl -X POST http://localhost:8900/infer/batch \
  -H "Content-Type: application/json" \
  -d '{"texts": ["ì´ë©”ì¼: bob@test.io", "ì „í™”: 010-9876-5432"]}'

# 5. API ë¬¸ì„œ í™•ì¸
open http://localhost:8900/docs
```

## í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# pytest ì„¤ì¹˜ (requirements.txtì— í¬í•¨)
pip install pytest httpx

# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest

# ìƒì„¸ ì¶œë ¥
pytest -v

# íŠ¹ì • í…ŒìŠ¤íŠ¸ íŒŒì¼ë§Œ ì‹¤í–‰
pytest tests/test_smoke.py

# ì»¤ë²„ë¦¬ì§€ í™•ì¸
pytest --cov=app tests/
```

### í…ŒìŠ¤íŠ¸ êµ¬ì¡°

`tests/test_smoke.py`ëŠ” ì‹¤ì œ ëª¨ë¸ ì—†ì´ **FakeModel**ì„ ì‚¬ìš©í•˜ì—¬ API ì—”ë“œí¬ì¸íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:

- ì •ê·œì‹ ê¸°ë°˜ ê°„ë‹¨í•œ EMAIL/PHONE íƒì§€
- `/health`, `/labels`, `/infer`, `/infer/batch` ì—”ë“œí¬ì¸íŠ¸ ê²€ì¦
- ì‘ë‹µ êµ¬ì¡° ë° ë°ì´í„° í˜•ì‹ í™•ì¸
- ë°°ì¹˜ ì²˜ë¦¬ ë¡œì§ ê²€ì¦

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨
```bash
# ëª¨ë¸ íŒŒì¼ í™•ì¸
ls -lh xlmr-large-min/
# config.json, model.safetensors, tokenizer.json ë“±ì´ ìˆì–´ì•¼ í•¨

# SHA256 ì²´í¬ì„¬ ê²€ì¦
sha256sum -c xlmr-large-min.tar.zst.sha256

# ì¬ë‹¤ìš´ë¡œë“œ
rm -rf xlmr-large-min xlmr-large-min.tar.zst
wget https://github.com/BOB-DSPM/SAGE_Identity-AI/releases/download/v0.1.0/xlmr-large-min.tar.zst
tar --zstd -xf xlmr-large-min.tar.zst
```

### í¬íŠ¸ ì¶©ëŒ
```bash
# ì‚¬ìš© ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸
lsof -i :8900

# í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
kill $(lsof -ti tcp:8900)

# ë‹¤ë¥¸ í¬íŠ¸ ì‚¬ìš©
uvicorn app.main:app --port 8901 --reload
```

### CUDA Out of Memory
```bash
# CPU ëª¨ë“œë¡œ ì „í™˜
export DEVICE=cpu

# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸° (ì½”ë“œ ìˆ˜ì • í•„ìš”)
# runtime.pyì—ì„œ ë°°ì¹˜ ì²˜ë¦¬ ì‹œ chunk ë‹¨ìœ„ë¡œ ë¶„í• 
```

### CORS ì˜¤ë¥˜
```bash
# .env íŒŒì¼ì— ì˜¤ë¦¬ì§„ ì¶”ê°€
CORS_ALLOW_ORIGINS=https://myapp.example.com,https://admin.example.com

# ë˜ëŠ” main.pyì—ì„œ allow_origins ìˆ˜ì •
allow_origins=["*"]  # ê°œë°œ í™˜ê²½ì—ì„œë§Œ ì‚¬ìš©
```

### ëŠë¦° ì‘ë‹µ ì†ë„
```bash
# ì›Œë°ì—… í™œì„±í™” (ê¸°ë³¸ê°’)
export WARMUP=1

# GPU ì‚¬ìš© (CUDA ì„¤ì¹˜ í•„ìš”)
export DEVICE=cuda:0
pip install torch --index-url https://download.pytorch.org/whl/cu121

# ì›Œì»¤ ìˆ˜ ì¦ê°€ (í”„ë¡œë•ì…˜)
uvicorn app.main:app --workers 4 --port 8900
```

## í”„ë¡œë•ì…˜ ë°°í¬

### ê¶Œì¥ ì‚¬í•­
- **ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ**: Nginx ë˜ëŠ” Traefikì„ í†µí•œ HTTPS ì„¤ì •
- **í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬**: systemd, Supervisor, PM2ë¡œ ìë™ ì¬ì‹œì‘
- **ë¡œê¹…**: êµ¬ì¡°í™”ëœ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì—°ë™
- **ë³´ì•ˆ**: API í‚¤ ì¸ì¦, Rate Limiting ì¶”ê°€
- **ì„±ëŠ¥**: GPU ì‚¬ìš© ì‹œ ë°°ì¹˜ í¬ê¸° ì¡°ì • ë° ì›Œì»¤ ìˆ˜ ì¦ê°€

### Systemd ì„œë¹„ìŠ¤ ì˜ˆì‹œ
```bash
# /etc/systemd/system/sage-identity-ai.service
[Unit]
Description=SAGE Identity-AI Service
After=network.target

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/home/ubuntu/SAGE_Identity-AI
Environment="MODEL_DIR=/home/ubuntu/SAGE_Identity-AI/xlmr-large-min"
Environment="DEVICE=cpu"
ExecStart=/home/ubuntu/SAGE_Identity-AI/.venv/bin/uvicorn app.main:app --host 0.0.0.0 --port 8900
Restart=always

[Install]
WantedBy=multi-user.target
```

```bash
# ì„œë¹„ìŠ¤ ë“±ë¡ ë° ì‹œì‘
sudo systemctl daemon-reload
sudo systemctl enable sage-identity-ai
sudo systemctl start sage-identity-ai
sudo systemctl status sage-identity-ai
```